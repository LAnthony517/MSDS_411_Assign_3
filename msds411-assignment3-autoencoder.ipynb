{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 411 Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.400139,
     "end_time": "2021-03-20T22:01:38.438205",
     "exception": false,
     "start_time": "2021-03-20T22:01:31.038066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.datasets\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "tensorflow.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "# tensorflow.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01258,
     "end_time": "2021-03-20T22:01:38.463626",
     "exception": false,
     "start_time": "2021-03-20T22:01:38.451046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = pd.read_csv('input/Kannada-MNIST/train.csv')\n",
    "#test = pd.read_csv('input/Kannada-MNIST/test.csv')\n",
    "train = pd.read_csv('train_X.csv')\n",
    "train_y = pd.read_csv('train_y.csv')\n",
    "test = pd.read_csv('test_X.csv')\n",
    "full_train = train.merge(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.read_csv('test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop(columns = {'Unnamed: 0'})\n",
    "train_y = train_y.drop(columns = {'Unnamed: 0'})\n",
    "test_y = test_y.drop(columns = {'Unnamed: 0'})\n",
    "test = test.drop(columns = {'Unnamed: 0'})\n",
    "full_train = full_train.drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "full_train['x'] = pd.get_dummies(full_train['x'], drop_first=True)\n",
    "\n",
    "train_y['x'] = pd.get_dummies(train_y['x'], drop_first=True)\n",
    "test_y['x'] = pd.get_dummies(test_y['x'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Train all layers at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 24 # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "encoding_dim1 = 11 \n",
    "\n",
    "\n",
    "input_img = keras.Input(shape =  (44,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = keras.layers.Dense(encoding_dim, activation='tanh')(input_img)\n",
    "\n",
    "encoded1 = keras.layers.Dense(encoding_dim1)(encoded)\n",
    "\n",
    "\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = keras.layers.Dense(44, activation='softplus')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "#encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "#decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "#decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='Adadelta', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorflow.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "\n",
    "history = autoencoder.fit(train, train,\n",
    "                epochs=3000,\n",
    "                batch_size=2200,\n",
    "                shuffle=False,\n",
    "                validation_data=(test, test))\n",
    "\n",
    "# history = autoencoder.fit(train, train, epochs=200,validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.get_weights()\n",
    "\n",
    "# Saving the weights from this model as well\n",
    "autoencoder.save('autoencoder_classification.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data Before and After Encoding/Decoding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T23:01:55.218189Z",
     "iopub.status.busy": "2021-05-29T23:01:55.217738Z",
     "iopub.status.idle": "2021-05-29T23:01:55.782541Z",
     "shell.execute_reply": "2021-05-29T23:01:55.781592Z",
     "shell.execute_reply.started": "2021-05-29T23:01:55.218156Z"
    }
   },
   "source": [
    "show_reconstructions(stacked_ae)\n",
    "#save_fig(\"reconstruction_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_valid_compressed = autoencoder.predict(test)\n",
    "tsne = TSNE()\n",
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
    "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1],c=test_y['x'], s=10, cmap=\"tab10\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this diagram a bit prettier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using Encoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ae_train = autoencoder.predict(train)\n",
    "ae_test = autoencoder.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AE Predictions for Log Regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train.shape\n",
    "ae_train_df = pd.DataFrame(ae_train)\n",
    "ae_train_df.to_csv('C:/Users/brook/Documents/MSDS/MSDS 411/Assignment 3/ae_train.csv')\n",
    "\n",
    "ae_test_df = pd.DataFrame(ae_test)\n",
    "ae_test_df.to_csv('C:/Users/brook/Documents/MSDS/MSDS 411/Assignment 3/ae_test.csv')\n",
    "\n",
    "\n",
    "ae_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "log_model = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\", C=1.5,fit_intercept = True, max_iter=1500, \n",
    "                               multi_class ='auto', warm_start = True)\n",
    "log_model.fit(ae_train, train_y)\n",
    "print(\"Training Set Score: {:.3f}\".format(log_model.score(ae_train, train_y)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "predictions = log_model.predict(ae_test)\n",
    "print(\"Train_Test Set Score: {:.3f}\".format(log_model.score(ae_test, test_y)*100))\n",
    "acc_log = round(roc_auc_score(test_y, predictions)*100 , 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal cutoff for predicting bad credit set as\n",
    "# (cost of false negative/cost of false positive) times\n",
    "# (prevalence of positive/prevalence of negative)\n",
    "# (1/5)*(.3/.7) = 0.086\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(test_y, predictions, normalize=False)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(classification_report(test_y,predictions))\n",
    "print(confusion_matrix(test_y,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(test_y, predictions)\n",
    "plt.plot(recalls, precisions, label = 'prec-recall')\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Precision-Recall\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder encoding into Log Regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from file\n",
    "encoder =tf.keras.models.load_model('autoencoder_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "denoising_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[44,]),\n",
    "    keras.layers.GaussianNoise(0.04),\n",
    "    keras.layers.Dense(22, activation=\"relu\"),\n",
    "    keras.layers.Dense(13, activation=\"relu\")\n",
    "])\n",
    "denoising_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(22, activation=\"relu\", input_shape=[13]),\n",
    "    keras.layers.Dense(44, activation=\"relu\")\n",
    "])\n",
    "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\n",
    "denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adadelta(lr=1),\n",
    "                     metrics=[rounded_accuracy])\n",
    "history = denoising_ae.fit(train, train, epochs=2000,\n",
    "                            batch_size=20,\n",
    "                           validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the train data\n",
    "X_train_encode = denoising_ae.predict(train)\n",
    "# encode the test data\n",
    "X_test_encode = denoising_ae.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model on the training set\n",
    "model.fit(X_train_encode, train_y)\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(test_y, yhat, normalize=False)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(classification_report(test_y,yhat))\n",
    "print(confusion_matrix(test_y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train = denoising_ae.predict(train)\n",
    "ae_test = denoising_ae.predict(test)\n",
    "\n",
    "ae_train.shape\n",
    "ae_train_df = pd.DataFrame(ae_train)\n",
    "ae_train_df.to_csv('C:/Users/brook/Documents/MSDS/MSDS 411/Assignment 3/ae_train.csv')\n",
    "\n",
    "ae_test_df = pd.DataFrame(ae_test)\n",
    "ae_test_df.to_csv('C:/Users/brook/Documents/MSDS/MSDS 411/Assignment 3/ae_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "pca = PCA(n_components=17, random_state = 42)\n",
    "start=datetime.now()\n",
    "pca = pca.fit(train)\n",
    "end=datetime.now()\n",
    "print(end-start)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var) + 1)]\n",
    "plt.figure(figsize=(25,15))\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('percentange of explained variance')\n",
    "plt.xlabel('principal component')\n",
    "plt.title('scree plot')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "train_features = pca.transform(train)\n",
    "\n",
    "log_model_pca = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\", C=1.5,fit_intercept = True, max_iter=1500, \n",
    "                               multi_class ='auto', warm_start = True)\n",
    "log_model_pca.fit(train_features, train_y)\n",
    "print(\"Training Set Score: {:.3f}\".format(log_model_pca.score(train_features, train_y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pca.transform(test)\n",
    "predictions_pca = log_model_pca.predict(test_features)\n",
    "print(\"Train_Test Set Score: {:.3f}\".format(log_model_pca.score(test_features, test_y)*100))\n",
    "acc_log_pca = round(roc_auc_score(test_y, predictions_pca)*100 , 2)\n",
    "acc_log_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(test_y, predictions_pca, normalize=False)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(classification_report(test_y,predictions_pca))\n",
    "print(confusion_matrix(test_y,predictions_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
